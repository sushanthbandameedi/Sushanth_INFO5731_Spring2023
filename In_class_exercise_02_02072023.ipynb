{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sushanthbandameedi/Sushanth_INFO5731_Spring2023/blob/main/In_class_exercise_02_02072023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "575KNS59-UHO"
      },
      "source": [
        "## The second In-class-exercise (02/07/2023, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wMabVE8-UHS"
      },
      "source": [
        "The purpose of this exercise is to understand users' information needs, then collect data from different sources for analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9kgSwnJ-UHT"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting research question (or practical question) you have in mind, what kind of data should be collected to answer the question(s)? How many data needed for the analysis? The detail steps for collecting and save the data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCW9XXee-UHU"
      },
      "outputs": [],
      "source": [
        "What elements influence Bitcoin's price volatility, and how does it stack up against other significant cryptocurrencies, is my research topic.\n",
        "The data that must be gathered includes past daily closing values for Bitcoin and other significant cryptocurrencies, data on each cryptocurrency's market capitalisation, each cryptocurrency's volume traded on different exchanges, cryptocurrency-related news items and sentiment analysis of such posts, Rates of interest, hyperinflation, and market sentiment are examples of economic indicators.\n",
        "Some few years' amount of data (about 1000–1500 data points) ought to be adequate as I'm performing an analysis every day.\n",
        "Steps needed to collect and save data:\n",
        "1. Scrape historical data on market capitalization, volume, and daily closing prices from a dependable source like CoinMarketCap or CoinGecko.\n",
        "2. Gather news items on cryptocurrency using web scraping techniques, then use natural language processing to analyze sentiment.\n",
        "3. Download pertinent economic data from sources that are openly accessible, such as the World Bank or the Federal Reserve.\n",
        "4. Keep the data in a database or CSV file that may be used for analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sG7G-Yvv-UHV"
      },
      "source": [
        "Question 2 (10 points): Write python code to collect 1000 data samples you discussed above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "47_5jMCj-UHV"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Making GET request to the URL which contains the data\n",
        "url = \"https://coinmarketcap.com/currencies/bitcoin/historical-data/?start=20220101&end=20221231\"\n",
        "response = requests.get(url)\n",
        "\n",
        "# Using BeautifulSoup for parsing the HTML code of that page\n",
        "soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "# Finding the table containing the data\n",
        "table = soup.find(\"table\", {\"class\": \"sc-f7a61dda-3 bdlBYm cmc-table  \"})\n",
        "\n",
        "# Extracting the headers and data rows from the table\n",
        "headers = [header.text for header in table.find(\"thead\").find_all(\"th\")]\n",
        "rows = []\n",
        "for row in table.find(\"tbody\").find_all(\"tr\"):\n",
        "    cells = [cell.text.strip() for cell in row.find_all(\"td\")]\n",
        "    rows.append(cells)\n",
        "\n",
        "# Converting the data to a pandas DataFrame\n",
        "df = pd.DataFrame(rows, columns=headers)\n",
        "\n",
        "# Saving the data to a CSV file\n",
        "df.to_csv(\"bitcoin_data.csv\", index=False)\n",
        "\n",
        "# Selecting the first 1000 rows of the DataFrame for analysis\n",
        "df = df[:1000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRGXhN-U-UHV"
      },
      "source": [
        "Question 3 (10 points): Write python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"information retrieval\". The articles should be published in the last 10 years (2012-2022).\n",
        "\n",
        "The following information of the article needs to be collected:\n",
        "\n",
        "(1) Title\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3eK8-Vc-UHW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "2b6bcb70-02a5-4bde-f70e-afcf46602a86"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-8f2750d80aae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;31m# year , author , publication of the paper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m \u001b[0myear\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mpublication\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mauthor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_author_year_publi_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthor_tag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ],
      "source": [
        "# You code here (Please add comments in the code):\n",
        "#importing the required libraries\n",
        "import requests \n",
        "import json\n",
        "import time\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "headers = {'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.114 Safari/537.36'}\n",
        "# this function for the extracting information of the tags\n",
        "def get_tags(doc):\n",
        "    paper_tag = doc.select('[data-lid]')\n",
        "    link_tag = doc.find_all('h3',{\"class\" : \"gs_rt\"})\n",
        "    author_tag = doc.find_all(\"div\", {\"class\": \"gs_a\"})\n",
        "\n",
        "    return paper_tag,link_tag,author_tag\n",
        "\n",
        "# it will return the title of the paper\n",
        "def get_papertitle(paper_tag):\n",
        "  \n",
        "  paper_names = []\n",
        "  \n",
        "  for tag in paper_tag:\n",
        "    paper_names.append(tag.select('h3')[0].get_text())\n",
        "\n",
        "    return paper_names\n",
        "\n",
        "\n",
        "\n",
        "# function for the getting autho , year and publication information\n",
        "def get_author_year_publi_info(authors_tag):\n",
        "    years = []\n",
        "    publication = []\n",
        "    authors = []\n",
        "    for i in range(len(authors_tag)):\n",
        "        authortag_text = (authors_tag[i].text).split()\n",
        "        year = int(re.search(r'\\d+', authors_tag[i].text).group())\n",
        "        years.append(year)\n",
        "        publication.append(authortag_text[-1])\n",
        "        author = authortag_text[0] + ' ' + re.sub(',','', authortag_text[1])\n",
        "        authors.append(author)\n",
        "  \n",
        "        return years , publication, authors\n",
        "\n",
        "# creating final repository\n",
        "paper_repos_dict = {\n",
        "                    'Paper Title' : [],\n",
        "                    'Year' : [],\n",
        "                    'Author' : [],\n",
        "                    'Publication' : []\n",
        "                     }\n",
        "\n",
        "# adding information in repository\n",
        "def add_in_paper_repo(papername,year,author,publi):\n",
        "    paper_repos_dict['Paper Title'].extend(papername)\n",
        "    paper_repos_dict['Year'].extend(year)\n",
        "    paper_repos_dict['Author'].extend(author)\n",
        "    paper_repos_dict['Publication'].extend(publi)\n",
        "    return pd.DataFrame(paper_repos_dict)\n",
        "\n",
        "\n",
        "for i in range(0,1000):\n",
        "\n",
        "# getting url for the each page with keywor \"information retrieval from 2012 to 2022\"\n",
        " url = \"https://scholar.google.com/scholar?start={}&q=information+retrieval+2012+to+2022&hl=en&as_sdt=0,5\".format(i)\n",
        "response=requests.get(url,headers=headers)\n",
        "page_contents = response.text\n",
        "doc = BeautifulSoup(page_contents,'html.parser')\n",
        "\n",
        "paper_tag,link_tag,author_tag = get_tags(doc)\n",
        "papername = get_papertitle(paper_tag)\n",
        "\n",
        "# year , author , publication of the paper\n",
        "year , publication , author = get_author_year_publi_info(author_tag)\n",
        "\n",
        " \n",
        "\n",
        " \n",
        "\n",
        " #add in paper repo dict\n",
        "final = add_in_paper_repo(papername,year,author,publication)\n",
        "  \n",
        "  # use sleep to avoid status code 429\n",
        "time.sleep(30)\n",
        "final.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc_X6JHP-UHW"
      },
      "source": [
        "Question 4 (10 points): Write python code to collect 1000 posts from Twitter, or Facebook, or Instagram. You can either use hashtags, keywords, user_name, user_id, or other information to collect the data. \n",
        "\n",
        "The following information needs to be collected:\n",
        "\n",
        "(1) User_name\n",
        "\n",
        "(2) Posted time\n",
        "\n",
        "(3) Text "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "HWnNoq-r-UHW",
        "outputId": "1f29aaac-aba0-4aca-9421-7194c67fd95a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-9ab50abe159a>:16: FutureWarning: username is deprecated, use user.username instead\n",
            "  tweets.append([tweet.username, tweet.date, tweet.content])\n",
            "<ipython-input-6-9ab50abe159a>:16: FutureWarning: content is deprecated, use rawContent instead\n",
            "  tweets.append([tweet.username, tweet.date, tweet.content])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Username_name               Posted time  \\\n",
              "0          7hate91 2023-02-13 03:44:16+00:00   \n",
              "1     fifthorseman 2023-02-13 03:44:16+00:00   \n",
              "2  sneaker2speaker 2023-02-13 03:44:16+00:00   \n",
              "3        jaynee724 2023-02-13 03:44:16+00:00   \n",
              "4         JPDunks4 2023-02-13 03:44:16+00:00   \n",
              "\n",
              "                                                Text  \n",
              "0                 Up chiefs \\n#FentyBowl  #SuperBowl  \n",
              "1  @FutureCanes 25 years calling the game and you...  \n",
              "2  @academic_la Four exceptions.\\n#NFL Refs must ...  \n",
              "3  Do the Super Bowl winners actually go to Disne...  \n",
              "4  Good Superbowl ruined by 1 call.  NFL needs to...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-61c1420b-d5c9-4f57-b3c9-b5b597b9c8d5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Username_name</th>\n",
              "      <th>Posted time</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7hate91</td>\n",
              "      <td>2023-02-13 03:44:16+00:00</td>\n",
              "      <td>Up chiefs \\n#FentyBowl  #SuperBowl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>fifthorseman</td>\n",
              "      <td>2023-02-13 03:44:16+00:00</td>\n",
              "      <td>@FutureCanes 25 years calling the game and you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sneaker2speaker</td>\n",
              "      <td>2023-02-13 03:44:16+00:00</td>\n",
              "      <td>@academic_la Four exceptions.\\n#NFL Refs must ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>jaynee724</td>\n",
              "      <td>2023-02-13 03:44:16+00:00</td>\n",
              "      <td>Do the Super Bowl winners actually go to Disne...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>JPDunks4</td>\n",
              "      <td>2023-02-13 03:44:16+00:00</td>\n",
              "      <td>Good Superbowl ruined by 1 call.  NFL needs to...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-61c1420b-d5c9-4f57-b3c9-b5b597b9c8d5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-61c1420b-d5c9-4f57-b3c9-b5b597b9c8d5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-61c1420b-d5c9-4f57-b3c9-b5b597b9c8d5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import snscrape.modules.twitter as sntwitter # for twitter webscraping without api\n",
        "import pandas as pd # To  store the scraped data\n",
        "\n",
        "query = \"superbowl\" #twitter hashtag\n",
        "tweets = []\n",
        "limit = 1000      #1000 limit\n",
        "\n",
        "\n",
        "for tweet in sntwitter.TwitterSearchScraper(query).get_items():\n",
        "    \n",
        "    # print(vars(tweet))\n",
        "    # break\n",
        "    if len(tweets) == limit: #to make sure we have 1000 tweets\n",
        "        break\n",
        "    else:\n",
        "        tweets.append([tweet.username, tweet.date, tweet.content])\n",
        "        \n",
        "df = pd.DataFrame(tweets, columns=['Username_name', 'Posted time', 'Text']) #storing the data into a dataframe\n",
        "print(df) #printing the data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install snscrape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tl7kT2WFkcSU",
        "outputId": "2200da25-04b7-4735-e317-5fe33eb1dfc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting snscrape\n",
            "  Downloading snscrape-0.5.0.20230113-py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 KB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from snscrape) (2.25.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from snscrape) (3.9.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.8/dist-packages (from snscrape) (2022.7.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from snscrape) (4.9.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from snscrape) (4.6.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (2022.12.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (1.7.1)\n",
            "Installing collected packages: snscrape\n",
            "Successfully installed snscrape-0.5.0.20230113\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}